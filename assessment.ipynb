{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14925000-fbff-4a92-a451-bf3008e8aa6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>8</td><td>None</td><td>pyspark</td><td>idle</td><td></td><td></td><td>None</td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as Type\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "676d2bbf-a01a-4eed-b18b-4baf637e614d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"ExcelReadExample\").getOrCreate()\n",
    "excel_file_path = r'/home/glue_user/workspace/jupyter_workspace/Input_v2.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73f0c36a-4964-4ad4-b2e1-1e86668b981c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# class DataValidator:\n",
    "    # def __init__(self, excel_file_path):\n",
    "    #     self.file_path = excel_file_path\n",
    "    #     self.spark = SparkSession.builder.appName(\"Project1\").getOrCreate()\n",
    "\n",
    "def read_file(excel_file_path):\n",
    "    df_pd = pd.read_excel(excel_file_path, engine='openpyxl')\n",
    "    df0 = spark.createDataFrame(df_pd)\n",
    "    return df0\n",
    "\n",
    "# ----------------------- exploratory data analysis ----------------------- \n",
    "\n",
    "def data_analysis(excel_file_path):\n",
    "    df0 = read_file(excel_file_path)\n",
    "\n",
    "    # schema\n",
    "    print(f'1. data schema')\n",
    "    df0.printSchema()\n",
    "\n",
    "    # statistical data summary\n",
    "    print(f'2. statistical data summary')\n",
    "    df0.describe().show()\n",
    "\n",
    "    # check duplicates\n",
    "    print(f'3. check duplicates')\n",
    "    df0.groupBy(df0.columns).count().where(F.col('count') > 1).select(F.sum('count')).show()\n",
    "\n",
    "    print(f'4. sample data')\n",
    "    df0.show(5, truncate=False)\n",
    "\n",
    "    # check NaN / NULL / empty string\n",
    "    print(f'5. check NaN / NULL / empty string')\n",
    "    for col, data_type in df0.dtypes:\n",
    "        nan_count = df0.filter(F.isnan(F.col(col))).count()\n",
    "        null_count = df0.filter(F.col(col).isNull()).count()\n",
    "        empty_str_count = df0.filter(F.col(col)=='').count()\n",
    "\n",
    "        if (nan_count > 0) or (null_count > 0) or (empty_str_count > 0):\n",
    "            print(f\"{col} with {data_type} -> nan: {nan_count}, null: {null_count}, '': {empty_str_count}\")\n",
    "\n",
    "def general_preprocess(excel_file_path, remove_nan=False):\n",
    "    df0 = read_file(excel_file_path)\n",
    "\n",
    "    # ----------------------- data pre-processing -----------------------\n",
    "\n",
    "    # preprocess for column header\n",
    "    # 1. remove leading and trailing space\n",
    "    # 2. replace ' ' with '_'\n",
    "    # 3. change uppercase char to lowercase char\n",
    "\n",
    "    df1 = df0.select([F.col(col).alias(col.strip().replace(\" \", \"_\").lower()) for col in df0.columns])\n",
    "    \n",
    "    if remove_nan is True:\n",
    "        df1 = df1.na.drop()\n",
    "        \n",
    "    # cast double / long data type into int\n",
    "    for col, data_type in df1.dtypes:\n",
    "        if data_type != 'string':\n",
    "            df1 = df1.withColumn(col, df1[col].cast(Type.IntegerType()))\n",
    "\n",
    "    return df1\n",
    "\n",
    "\n",
    "def eliminate_outliers(df, col_name):\n",
    "    outlier_threshold = 3\n",
    "    stats_summary = df.describe(col_name)\n",
    "    mean_val = stats_summary.filter(stats_summary[\"summary\"] == \"mean\").select(col_name).collect()[0][col_name]\n",
    "    stddev_val = stats_summary.filter(stats_summary[\"summary\"] == \"stddev\").select(col_name).collect()[0][col_name]\n",
    "\n",
    "    df_with_z_score = df.withColumn(f\"{col_name}_z_score\", (F.col(col_name) - mean_val) / stddev_val)\n",
    "\n",
    "    df_final = df_with_z_score.filter(F.abs(F.col(f\"{col_name}_z_score\")) < outlier_threshold) \\\n",
    "                                .drop(f\"{column_name}_z_score\")\n",
    "\n",
    "    return df_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2648b40-48af-4db8-9aa5-0c31b8bd834e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/glue_user/spark/python/pyspark/sql/pandas/conversion.py:474: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for column, series in pdf.iteritems():\n",
      "/home/glue_user/spark/python/pyspark/sql/pandas/conversion.py:486: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for column, series in pdf.iteritems():"
     ]
    }
   ],
   "source": [
    "# ----------------------- question 1: group_by_age function -----------------------\n",
    "\n",
    "def group_by_age(excel_file_path):\n",
    "    df0 = general_preprocess(excel_file_path, remove_nan=True)\n",
    "\n",
    "    curr_year = datetime.today().year\n",
    "\n",
    "    # get age for each person\n",
    "    df1 = df0.withColumn(\"age\", curr_year - F.col(\"birth_year\"))\n",
    "\n",
    "    # Group by age and collect names into lists\n",
    "    result_dict = (\n",
    "                df1.groupBy(\"age\")\n",
    "                .agg({\"name\": \"collect_list\"})\n",
    "                .withColumnRenamed(\"collect_list(name)\", \"names\")  # collect categorized name into a list\n",
    "                .orderBy(\"age\")\n",
    "                .select(\"age\", \"names\")\n",
    "                .rdd.collectAsMap()  # df -> rdd -> dict\n",
    "    )\n",
    "\n",
    "#     null_names = df0.filter(F.isnan(F.col(\"birth_year\"))) \\\n",
    "#         .select(\"name\") \\\n",
    "#         .rdd.flatMap(list).collect()\n",
    "\n",
    "#     result_dict['NA'] = null_names\n",
    "    \n",
    "    return result_dict\n",
    "\n",
    "result = group_by_age(excel_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c937a4c7-8279-4b8f-8d27-c5794e3e4c55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Blair', 'Blake', 'Brent', 'Archibald', 'Atwater', 'Avery', 'Jed', 'Keene', 'Keith', 'Kim', 'Grant', 'Hal', 'Ian', 'Isaac']\n",
      "/home/glue_user/spark/python/pyspark/sql/pandas/conversion.py:474: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for column, series in pdf.iteritems():\n",
      "/home/glue_user/spark/python/pyspark/sql/pandas/conversion.py:486: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for column, series in pdf.iteritems():"
     ]
    }
   ],
   "source": [
    "# ----------------------- question 2: vowel in middle of the name -----------------------\n",
    "\n",
    "def check_vowel(excel_file_path):\n",
    "    df1 = general_preprocess(excel_file_path)\n",
    "\n",
    "    # Define a UDF with a lambda function\n",
    "    udf_is_vowel = F.udf(lambda name: len(name) % 2 == 1 and name[len(name)//2].lower() in ['a', 'e', 'i'], Type.BooleanType())\n",
    "\n",
    "    # Add a new column \"HasVowelInMiddle\"\n",
    "    df2 = df1.withColumn(\"vowel_in_middle\", udf_is_vowel(F.col(\"name\")))\n",
    "\n",
    "    # collect into list\n",
    "    result = df2.filter(\"vowel_in_middle == True\").select(\"name\").rdd.flatMap(lambda x: x).collect()\n",
    "\n",
    "    return result\n",
    "\n",
    "result = check_vowel(excel_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51b44f42-e88a-4c06-954f-4246828fb3e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------+----------+------------+------------+-------------+-------+----------+---+---------+\n",
      "| id|        name|birth_year|assignment_a|assignment_b|mid_term_exam|project|final_exam|age|AGE_GROUP|\n",
      "+---+------------+----------+------------+------------+-------------+-------+----------+---+---------+\n",
      "|D95|        Bert|      1985|          58|          70|           66|     90|        95| 39|    YOUNG|\n",
      "|I67|       Bevis|      1965|          63|          65|           74|     75|        99| 59|      OLD|\n",
      "|H45|      Blaine|      1984|          57|           0|           62|     90|        91| 40|      OLD|\n",
      "|A68|       Blair|      1974|          90|          73|           59|     85|        94| 50|      OLD|\n",
      "|B45|       Blake|      1955|          73|          56|           77|     95|        46| 69|      OLD|\n",
      "|G56|        Bond|      1978|          99|          43|           73|     85|        75| 46|      OLD|\n",
      "|C87|       Boris|      1984|          88|           0|           82|     85|        84| 40|      OLD|\n",
      "|E23|       Bowen|      1965|          92|          72|           61|     85|        96| 59|      OLD|\n",
      "|F98|      Braden|      1984|          69|          49|           67|     70|        89| 40|      OLD|\n",
      "|G56|     Bradley|      1985|          99|          95|           63|     70|        86| 39|    YOUNG|\n",
      "|F91|     Brandan|      1965|          90|          86|           92|     80|        98| 59|      OLD|\n",
      "|K52|     Calvert|      1985|          77|          74|           52|     95|        83| 39|    YOUNG|\n",
      "|A68|    Caldwell|      1985|          78|          90|           68|     70|        81| 39|    YOUNG|\n",
      "|L79|       Caleb|      1990|          94|          88|           72|     85|        92| 34|    YOUNG|\n",
      "|M34|      Calvin|      1993|          83|          78|           58|     80|        63| 31|    YOUNG|\n",
      "|N92|     Carrick|      1967|          95|          88|           71|     60|        93| 57|      OLD|\n",
      "|I67|        Carl|      1945|           0|          60|           68|     85|        57| 79|      OLD|\n",
      "|D39|     Carlton|      1956|          56|          56|           72|     85|        54| 68|      OLD|\n",
      "|W71|      Carney|      1990|          53|          71|           77|     90|        59| 34|    YOUNG|\n",
      "|Q28|     Carroll|      1991|          88|           0|           82|     85|        84| 33|    YOUNG|\n",
      "|V83|      Carter|      1985|          92|          72|           61|     85|        96| 39|    YOUNG|\n",
      "|X72|      Carver|      1987|          69|          49|           67|     70|        89| 37|    YOUNG|\n",
      "|Z18|        Cary|      1967|          99|          95|           63|     70|        86| 57|      OLD|\n",
      "|B91|      Casper|      1988|          90|          86|           92|     80|        98| 36|    YOUNG|\n",
      "|C55|       Cecil|      1985|          70|          93|           77|     75|        75| 39|    YOUNG|\n",
      "|D10|      Cedric|      1967|          77|          74|           52|     95|        83| 57|      OLD|\n",
      "|D16|     Anthony|      1995|          78|          90|           68|     70|        81| 29|    YOUNG|\n",
      "|E81|      Archer|      2000|          58|          70|           66|     90|        95| 24|    YOUNG|\n",
      "|E92|   Archibald|      1984|          63|          65|           74|     75|        99| 40|      OLD|\n",
      "|E10|       Arlen|      1978|          83|          78|           58|     80|        63| 46|      OLD|\n",
      "|F28|      Arnold|      1985|          95|          88|           71|     60|        93| 39|    YOUNG|\n",
      "|F38|      Arthur|      1945|           0|          60|           68|     85|        57| 79|      OLD|\n",
      "|G76|     Atwater|      1977|          83|          78|           58|     80|        63| 47|      OLD|\n",
      "|G45|      Atwood|      1985|          95|          88|           71|     60|        93| 39|    YOUNG|\n",
      "|G34|      Aubrey|      1965|           0|          60|           68|     85|        57| 59|      OLD|\n",
      "|H53|      Austin|      1956|          99|          95|           63|     70|        86| 68|      OLD|\n",
      "|H25|       Avery|      2000|          99|          95|           63|     70|        86| 24|    YOUNG|\n",
      "|J29|        Jack|      1991|          90|          86|           92|     80|        98| 33|    YOUNG|\n",
      "|H65|       Jacob|      1985|          70|          93|           77|     75|        75| 39|    YOUNG|\n",
      "|I35|       James|      1987|          77|          74|           52|     95|        83| 37|    YOUNG|\n",
      "|I37|      Jarvis|      1967|          77|          74|           52|     95|        83| 57|      OLD|\n",
      "|I72|       Jason|      1965|          78|         110|           68|     70|        81| 59|      OLD|\n",
      "|J29|      Jasper|      1988|          58|          70|           66|     90|        95| 36|    YOUNG|\n",
      "|J62|         Jed|      1985|          63|          65|           74|     75|        99| 39|    YOUNG|\n",
      "|J54|     Jeffrey|      1967|          83|          78|           58|     80|         0| 57|      OLD|\n",
      "|J38|    Jeremiah|      1985|          95|          88|           71|     60|        93| 39|    YOUNG|\n",
      "|K56|      Jerome|      1965|           0|          60|           68|     85|        57| 59|      OLD|\n",
      "|K82|       Jesse|      1984|          94|          88|           72|     85|        92| 40|      OLD|\n",
      "|K36|        John|      1985|          70|          93|           77|     75|        75| 39|    YOUNG|\n",
      "|L36|    Jonathan|      1985|          77|          74|           52|     95|        83| 39|    YOUNG|\n",
      "|L92|        Kane|      1990|          77|          74|           52|     95|        83| 34|    YOUNG|\n",
      "|L10|       Keene|      1993|          78|          90|           68|     70|        81| 31|    YOUNG|\n",
      "|M10|      Keegan|      1965|          58|          70|           66|     90|        95| 59|      OLD|\n",
      "|M28|      Keaton|      1988|          63|          65|           74|     75|        99| 36|    YOUNG|\n",
      "|M30|       Keith|      1985|          83|          78|           58|     80|        63| 39|    YOUNG|\n",
      "|N90|      Kelsey|      1967|          95|          88|           71|     60|        93| 57|      OLD|\n",
      "|N65|      Kelvin|      1995|           0|          60|           68|     85|        57| 29|    YOUNG|\n",
      "|Q28|     Kendall|      2000|          94|          88|           72|     85|        92| 24|    YOUNG|\n",
      "|T80|    Kendrick|      1984|          78|          90|           68|     70|        81| 40|      OLD|\n",
      "|R90|Kenneth, Ken|      1978|          58|          70|           66|     90|        95| 46|      OLD|\n",
      "|U67|        Kent|      1985|          63|          65|           74|     75|        99| 39|    YOUNG|\n",
      "|Q76|      Kenway|      1956|          83|          78|           58|     80|        63| 68|      OLD|\n",
      "|P65|      Kenyon|      1990|          95|          88|           71|     60|        93| 34|    YOUNG|\n",
      "|T29|       Kerry|      1991|           0|          60|           68|     85|        57| 33|    YOUNG|\n",
      "|S38|      Kerwin|      1985|          94|          88|           72|     85|        92| 39|    YOUNG|\n",
      "|W67|       Kevin|      1987|          70|          93|           77|     75|        75| 37|    YOUNG|\n",
      "|R98|      Kiefer|      1967|          77|          74|           52|     95|        83| 57|      OLD|\n",
      "|L20|       Kilby|      1965|          77|          74|           52|     95|        83| 59|      OLD|\n",
      "|T39|      Kilian|      1988|          78|          90|           68|     70|        81| 36|    YOUNG|\n",
      "|Q55|         Kim|      1985|          58|          70|           66|     90|        95| 39|    YOUNG|\n",
      "|P50|     Kimball|      1967|          63|          65|          103|     75|        99| 57|      OLD|\n",
      "|K67|    Kingsley|      1995|          83|          78|           58|     80|        63| 29|    YOUNG|\n",
      "|S20|       Kirby|      2000|          95|          88|           71|     60|        93| 24|    YOUNG|\n",
      "|R87|        Kirk|      1992|           0|          60|           68|     85|        57| 32|    YOUNG|\n",
      "|D67|      Graham|      1998|          94|          88|           72|     85|        92| 26|    YOUNG|\n",
      "|T85|       Grant|      1957|         208|          90|           68|     70|        81| 67|      OLD|\n",
      "|P39|     Grayson|      1982|          58|          70|           66|     90|        95| 42|      OLD|\n",
      "|F46|     Gregory|      1980|          63|          65|           74|     75|        99| 44|      OLD|\n",
      "|U76|     Gresham|      1985|          83|          78|           58|     80|        63| 39|    YOUNG|\n",
      "|R30|    Griswald|      1987|          95|          88|           71|     60|        93| 37|    YOUNG|\n",
      "|Q45|      Grover|      1967|           0|          60|           68|     85|        57| 57|      OLD|\n",
      "|P20|         Guy|      1965|          94|          88|           72|     85|        92| 59|      OLD|\n",
      "|N45|      Hadden|      1988|          83|          78|           58|     80|        63| 36|    YOUNG|\n",
      "|M98|      Hadley|      1985|          95|          88|           71|     60|        93| 39|    YOUNG|\n",
      "|L24|      Hadwin|      1967|          83|          78|           58|     80|        63| 57|      OLD|\n",
      "|J67|     Halbert|      1988|           0|          60|           68|     85|        57| 36|    YOUNG|\n",
      "|I63|      Halden|      1985|          56|         101|           72|     85|        54| 39|    YOUNG|\n",
      "|H39|        Hale|      1967|          53|          71|           77|     90|        59| 57|      OLD|\n",
      "|G30|        Hall|      1995|          88|           0|           82|     85|        84| 29|    YOUNG|\n",
      "|F10|      Halsey|      2000|          92|          72|           61|     85|        96| 24|    YOUNG|\n",
      "|E48|      Hamlin|      1984|          69|          49|           67|     70|        89| 40|      OLD|\n",
      "|D98|         Ian|      1967|          99|          95|           63|     70|        86| 57|      OLD|\n",
      "|C91|        Igor|      1983|          99|          95|           63|     70|        86| 41|      OLD|\n",
      "|A34|       Irvin|      1995|          90|          86|           92|     80|        98| 29|    YOUNG|\n",
      "|B55|       Isaac|      1989|          70|          93|           77|     75|        75| 35|    YOUNG|\n",
      "|A45|        Ives|      2000|          77|          74|           52|     95|        83| 24|    YOUNG|\n",
      "+---+------------+----------+------------+------------+-------------+-------+----------+---+---------+\n",
      "\n",
      "/home/glue_user/spark/python/pyspark/sql/pandas/conversion.py:474: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for column, series in pdf.iteritems():\n",
      "/home/glue_user/spark/python/pyspark/sql/pandas/conversion.py:486: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for column, series in pdf.iteritems():"
     ]
    }
   ],
   "source": [
    "# ----------------------- question 3: age category -----------------------\n",
    "\n",
    "def age_category(excel_file_path):\n",
    "    df1 = general_preprocess(excel_file_path, remove_nan=True)\n",
    "\n",
    "    curr_year = datetime.today().year\n",
    "\n",
    "    # get age for each person\n",
    "    df1 = df1.withColumn(\"age\", curr_year - F.col(\"birth_year\"))\n",
    "\n",
    "    # age group\n",
    "    df1 = df1.withColumn(\n",
    "            'AGE_GROUP',\n",
    "            F.when(F.col(\"age\").between(0, 17), 'TEENAGER')\\\n",
    "            .when(F.col('age').between(18,39), 'YOUNG')\\\n",
    "            .when(F.col('age').between(40,100), 'OLD')\n",
    "            .otherwise('NA'))\n",
    "    \n",
    "    return df1\n",
    "\n",
    "df3 = age_category(excel_file_path)\n",
    "# df3.show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79c4e48a-f716-468e-92ff-ca2b2d443ef3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "has duplicates in id\n",
      "+---+-----+\n",
      "| id|count|\n",
      "+---+-----+\n",
      "|Q28|    2|\n",
      "|I67|    2|\n",
      "|J29|    3|\n",
      "|G56|    2|\n",
      "|A68|    2|\n",
      "+---+-----+\n",
      "\n",
      "/home/glue_user/spark/python/pyspark/sql/pandas/conversion.py:474: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for column, series in pdf.iteritems():\n",
      "/home/glue_user/spark/python/pyspark/sql/pandas/conversion.py:486: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for column, series in pdf.iteritems():"
     ]
    }
   ],
   "source": [
    "# ----------------------- question 4: check ID uniqueness  -----------------------\n",
    "def check_id_uniqueness(excel_file_path):\n",
    "    df1 = general_preprocess(excel_file_path)\n",
    "\n",
    "    if df1.count() > df1.dropDuplicates(['id']).count():\n",
    "        print('has duplicates in id')\n",
    "\n",
    "        df2 = df1.groupby(['id']) \\\n",
    "                    .count() \\\n",
    "                    .filter('count > 1') \\\n",
    "        \n",
    "        return df2\n",
    "\n",
    "    else:\n",
    "        print('no duplicate in id')\n",
    "\n",
    "        \n",
    "df = check_id_uniqueness(excel_file_path)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "506e456d-589e-4131-b609-cbe6513a50d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/glue_user/spark/python/pyspark/sql/pandas/conversion.py:474: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for column, series in pdf.iteritems():\n",
      "/home/glue_user/spark/python/pyspark/sql/pandas/conversion.py:486: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for column, series in pdf.iteritems():"
     ]
    }
   ],
   "source": [
    "# ----------------------- question 5: age group average  -----------------------\n",
    "\n",
    "\n",
    "def calculate_and_save_average_age(excel_file_path):\n",
    "    df3 = age_category(excel_file_path)\n",
    "\n",
    "    # partition by the age group set in previous question and find the average\n",
    "    window = Window.partitionBy(\"AGE_GROUP\")\n",
    "    avg_age = F.avg(\"age\").over(window)\n",
    "    df4 = df3.withColumn(\"AVERAGE\", F.round(avg_age, 2))\n",
    "\n",
    "    df4 = (df4.withColumnRenamed('id', 'ID')\n",
    "                    .withColumnRenamed('name', 'NAME')\n",
    "                    .withColumnRenamed('birth_year', 'BIRTHYEAR')\n",
    "                    .withColumnRenamed('age', 'AGE'))\n",
    "\n",
    "    # Get specific column and export .csv \n",
    "    df4.select(\"ID\", \"NAME\", \"BIRTHYEAR\", \"AGE\", \"AGE_GROUP\", \"AVERAGE\") \\\n",
    "             .write \\\n",
    "             .csv(\"output.csv\", header=True, mode=\"overwrite\")\n",
    "\n",
    "# calculate_and_save_average_age(excel_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2be5d6b2-3b93-4e6a-9750-345624f072c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'name', 'birth_year', 'assignment_a', 'assignment_b', 'mid_term_exam', 'project', 'final_exam']\n",
      "/home/glue_user/spark/python/pyspark/sql/pandas/conversion.py:474: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for column, series in pdf.iteritems():\n",
      "/home/glue_user/spark/python/pyspark/sql/pandas/conversion.py:486: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for column, series in pdf.iteritems():"
     ]
    }
   ],
   "source": [
    "df1 = general_preprocess(excel_file_path)\n",
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c661ecc1-1dac-4520-90c0-b8e9ae4afe15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+-------+-----------------+------------------+------------------+-----------------+-----------------+------------------+\n",
      "|summary|  id|   name|       birth_year|      assignment_a|      assignment_b|    mid_term_exam|          project|        final_exam|\n",
      "+-------+----+-------+-----------------+------------------+------------------+-----------------+-----------------+------------------+\n",
      "|  count| 100|    100|              100|               100|               100|              100|              100|               100|\n",
      "|   mean|null|   null|          1901.26|             74.11|             74.78|            68.29|            79.45|             81.09|\n",
      "| stddev|null|   null|390.2527443137901|29.798276338192327|20.271680001938915|9.580382945046473|9.997348133228614|16.520629894807644|\n",
      "|    min| A27|Anthony|                0|                 0|                 0|               52|               60|                 0|\n",
      "|    max| Z18|   Kirk|             2000|               208|               110|              103|               95|                99|\n",
      "+-------+----+-------+-----------------+------------------+------------------+-----------------+-----------------+------------------+\n",
      "\n",
      "+---+--------+----------+------------+------------+-------------+-------+----------+-----------------+\n",
      "| id|    name|birth_year|assignment_a|assignment_b|mid_term_exam|project|final_exam|            GRADE|\n",
      "+---+--------+----------+------------+------------+-------------+-------+----------+-----------------+\n",
      "|D95|    Bert|      1985|          58|          70|           66|     90|        95|            82.11|\n",
      "|I67|   Bevis|      1965|          63|          65|           74|     75|        99|            81.06|\n",
      "|H45|  Blaine|      1984|          57|           0|           62|     90|        91|            70.74|\n",
      "|A68|   Blair|      1974|          90|          73|           59|     85|        94|81.74000000000001|\n",
      "|B45|   Blake|      1955|          73|          56|           77|     95|        46|            67.64|\n",
      "|G56|    Bond|      1978|          99|          43|           73|     85|        75|            74.62|\n",
      "|C87|   Boris|      1984|          88|           0|           82|     85|        84|73.21000000000001|\n",
      "|E23|   Bowen|      1965|          92|          72|           61|     85|        96|            82.85|\n",
      "|F98|  Braden|      1984|          69|          49|           67|     70|        89|            73.25|\n",
      "|G56| Bradley|      1985|          99|          95|           63|     70|        86|            79.48|\n",
      "|F91| Brandan|      1965|          90|          86|           92|     80|        98|            90.18|\n",
      "|J29|   Brent|         0|          70|          93|           77|     75|        75|            77.39|\n",
      "|K52| Calvert|      1985|          77|          74|           52|     95|        83|78.21000000000001|\n",
      "|A68|Caldwell|      1985|          78|          90|           68|     70|        81|            76.61|\n",
      "|L79|   Caleb|      1990|          94|          88|           72|     85|        92|            85.87|\n",
      "|M34|  Calvin|      1993|          83|          78|           58|     80|        63|             69.6|\n",
      "|N92| Carrick|      1967|          95|          88|           71|     60|        93|            79.84|\n",
      "|I67|    Carl|      1945|           0|          60|           68|     85|        57|62.60000000000001|\n",
      "|D39| Carlton|      1956|          56|          56|           72|     85|        54|            65.75|\n",
      "|W71|  Carney|      1990|          53|          71|           77|     90|        59|71.49000000000001|\n",
      "+---+--------+----------+------------+------------+-------------+-------+----------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "/home/glue_user/spark/python/pyspark/sql/pandas/conversion.py:474: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for column, series in pdf.iteritems():\n",
      "/home/glue_user/spark/python/pyspark/sql/pandas/conversion.py:486: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for column, series in pdf.iteritems():"
     ]
    }
   ],
   "source": [
    "# ----------------------- question 6: get grades  -----------------------\n",
    "\n",
    "def get_grades(excel_file_path):\n",
    "    df1 = general_preprocess(excel_file_path)\n",
    "    \n",
    "    df1 = eliminate_outliers(df1, 'assignment_a')\n",
    "    eliminate_outliers(df1, 'assignment_b')\n",
    "    eliminate_outliers(df1, 'mid_term_exam')\n",
    "    eliminate_outliers(df1, 'project')\n",
    "    eliminate_outliers(df1, 'final_exam')\n",
    "\n",
    "    # provided weights\n",
    "    weights = {\n",
    "        \"assignment_a\": 0.07, \n",
    "        \"assignment_b\": 0.13, \n",
    "        \"mid_term_exam\": 0.20, \n",
    "        \"project\": 0.25, \n",
    "        \"final_exam\": 0.35\n",
    "    }\n",
    "\n",
    "    # create expression for weights\n",
    "    weighted_avg_expr = sum(F.col(criteria) * percentage for criteria, percentage in weights.items())\n",
    "\n",
    "    df1 = df1.withColumn(\"GRADE\", weighted_avg_expr)\n",
    "    \n",
    "    return df1\n",
    "\n",
    "# df3 = get_grades(excel_file_path)\n",
    "# df3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "35aab164-65bd-4950-bfe9-e300adc900a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ----------------------- question 7: draw a chart to show the trend of student -----------------------\n",
    "\n",
    "\n",
    "def return_chart_student_performance():\n",
    "    df = pd.read_excel(excel_file_path, engine='openpyxl')\n",
    "    df.columns = [col.strip().lower().replace(' ', '_') for col in df.columns]\n",
    "\n",
    "    df1 = df.query(\"\"\"\n",
    "        assignment_a <= 100 and \\\n",
    "        assignment_b <= 100 and \\\n",
    "        mid_term_exam <= 100 and \\\n",
    "        project <= 100 and \\\n",
    "        final_exam <= 100\n",
    "    \"\"\")\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    for index, row in df1.iterrows():\n",
    "        student_name = row['name']\n",
    "        student_scores = row[['assignment_a', 'assignment_b', 'mid_term_exam', 'project', 'final_exam']]\n",
    "\n",
    "        plt.plot(student_scores, label=student_name)\n",
    "\n",
    "    plt.xlabel('Assessment Type')\n",
    "    plt.ylabel('Score')\n",
    "    plt.title('Student Performance Trend During the Semester')\n",
    "    plt.xticks(range(5), ['Assignment A', 'Assignment B', 'Mid Term Exam', 'Project', 'Final Exam'])\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "return_chart_student_performance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a761f0-9a92-4ba1-925b-3c9a29da241e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
